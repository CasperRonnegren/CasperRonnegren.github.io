<!DOCTYPE HTML>
<html>
<head>
    <title>Casper Portfolio</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>
<body class="is-preload">
<div id="page-wrapper">

    <!-- Header -->
    <header id="header">
        <h1 id="logo"><a href="index.html">< Portfolio</a></h1>
        <nav id="nav">
        </nav>
    </header>

    <!-- Main -->
    <div id="main" class="wrapper style1">
        <div class="container">
            <header class="major"><h2>Optimizing Boids</h2></header>

            <!-- Introduction -->
            <div class="row gtr-150">
                <div class="col-12 col-12-medium">
                    <b class="image fit" style="background-color: #12151e ;"><img src="images/Boids/BoidsBannerReal.png" alt="" style="width: 80%; margin-left: auto; margin-right: auto"/></b>
                    <div class="col-12 col-12-medium"><h3>Introduction</h3></div>
                    <p style="margin-bottom: 0">
                        For this project, I went through the process of implementing <a href="https://en.wikipedia.org/wiki/Boids">Bird-Oid Objects</a> (Boids) through Unity's 
                        <a href="https://unity.com/resources/introduction-to-dots-ebook">Data-Oriented Technology Stack</a> (DOTS).
                        Implementing boids is something I had done before, so the goal this time around was to try and see how scalable I could make the implementation through the technologies available with DOTS.
                        While working on the project, I also learned of an optimization technique called 
                        <a href="https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/spatial-hashing-r2697/">Spatial Hashing</a>
                        and decided to incorporate into the final solution.
                        In the end, the two-faceted approach of utilizing both DOTS and Spatial Hashing proved to be an incredibly powerful combination that immensely improved scalability.
                    </p>
                </div>
                <div class="col-12 col-12-medium"><hr/></div>
            </div>

            <!-- Boids -->
            <div class="row gtr-150">
                <div class="col-12 col-12-medium">
                    <h3>Boids</h3>
                    <p>
                        The aim of boids is to simulate the flocking behavior of birds.
                        Flocking is accomplished through the combination of three <a href="https://www.red3d.com/cwr/steer/">Steering Behaviors</a> 
                        which each contribute a force used for the movement of a boid.
                        The three steering behaviors used in this case utilize the position and heading of other boids within a minimum distance
                        to calculate movement which emulates flocking behavior.
                    </p>
                </div>
                
                <div class="col-4 col-12-medium">
                    <b class="image fit"><img loading="lazy" src="images/Boids/Rule_separation.gif" alt="" /></b>
                    <p style="text-align: center"><b>Separation:</b> steer to avoid crowding local flockmates.</p>
                </div>
                <div class="col-4 col-12-medium">
                    <b class="image fit"><img loading="lazy" src="images/Boids/Rule_alignment.gif" alt="" /></b>
                    <p style="text-align: center"><b>Alignment:</b> steer towards the average heading of local flockmates.</p>
                </div>
                <div class="col-4 col-12-medium">
                    <b class="image fit"><img loading="lazy" src="images/Boids/Rule_cohesion.gif" alt="" /></b>
                    <p style="text-align: center"><b>Cohesion:</b> steer to move toward the average position of local flockmates.</p>
                </div>
                
                <div class="col-12 col-12-medium">
                    <p style="margin-bottom: 0">
                        Implementing steering behaviors is usually not too difficult as each one in isolation tends to be quite simple in their logic.
                        The tricky part is combining them as you have to intricately balance the force each steering behavior contributes towards the final behavior.
                        When you don't get the final behavior you want, it can be hard to tell which steering behavior is the cause of unintended movement, 
                        and whether the problem lies with the variables used or how the math itself is set up in the behaviour.
                        From my experience, it helps immensely to have gizmos display the different forces contributed by each steering behavior as it makes it easy
                        to see if any of them is doing something unintended.
                    </p>
                </div>
                <div class="col-12 col-12-medium"><hr/></div>
            </div>

            <!-- Optimization -->
            <div class="row gtr-150">
                <div class="col-12 col-12-medium">
                    <h3>Optimizations</h3>
                    <p>
                        The Data-Oriented Technology Stack Unity has is composed of three central technologies: the Entity Component System (ECS), the Job System, and the Burst Compiler.
                        The Unity ECS is a typical <a href="https://en.wikipedia.org/wiki/Entity_component_system">Entity Component System</a>, 
                        but integrated into the engine and works as an alternative to <a href="https://docs.unity3d.com/6000.2/Documentation/ScriptReference/MonoBehaviour.html">MonoBehaviour</a>.
                        As for the Job System, it is used to create multithreaded code by scheduling code as "jobs" to be done.
                        Finally, the Burst Compiler is black magic which you enable through a singular button press that somehow results in your code becoming 
                        faster by translating it into ancient forbidden scriptures.
                        In the end, most of the time spent in this project ended up going to learning how the ECS and Job Systems work and implementing boids through them.
                        The Burst Compiler does also have its own restrictions you need to work around, but you're pretty much already doing that when working with the ECS and Job System.
                    </p>
                    <p>
                        When it comes to scalability, a problem that becomes apparent with boids is that every boid has to iterate over all other boids to do the calculations 
                        for its steering behaviors. 
                        This entails an O(nÂ²) time complexity.
                        As boids too far away from each other won't even affect one another, a lot of processing time is essentially wasted just to find out if this is the case.
                        While doing a simple distance calculation is quite fast, when you have 40 000 boids that each needs to find the distance to the other 39 999 boids, the 
                        processing time adds up.
                        The worst part is that if the boids are set up to be sparse, it could very easily be the case that each individual boid won't even find themselves close
                        enough to affect even a small percentage of the other boids.
                        In my case with how I set it up, it was the norm that a boid wouldn't even affect 0.1% of the other 39 999 boids.
                        99.9% of the iterations boids do over each other are therefore just done to conclude that they aren't close enough to affect one another.
                    </p>
                    <p>
                        To reduce the amount of iterations boids need to do over each other, I implemented Spatial Hashing.
                        The optimization technique works by dividing space into discrete chunks.
                        A boid can find which chunk it's located in by doing a simple math calculation using its position.
                        All boids are put in a HashMap where the Key is the chunk and the Value is a collection of boids within that chunk.
                        Rather than having boids iterate over all other boids to find if they are close enough to affect each other, boids can instead look up the HashMap and only need to iterate over
                        boids within chunks that may contain ones which are close enough to fulfill the minimum distance requirement.
                        This can significantly reduce the amount of processing time required when managing a large amount of sparsely located boids.
                        The biggest cost from Spatial Hashing comes from setting up the HashMap which is done in O(n) time, but that is insignificant compared to what is won from filtering out all the
                        iterations that would otherwise result in nothing.
                    </p>
                </div>
                <div class="col-12 col-12-medium"><b class="image fit"><img loading="lazy" src="images/Boids/BoidsInAction.gif" alt="" /></b></div>
                <div class="col-12 col-12-medium">
                    <p style="margin-bottom: 0">
                        40 000 boids contained within a cube-shaped space. Boids are teleported to the opposite side when they go out of bounds.
                    </p>
                </div>
                
                <div class="col-12 col-12-medium"><hr/></div>
            </div>

            <!-- Results -->
            <div class="row gtr-150">
                <div class="col-12 col-12-medium"><h3>Results</h3>
                    <p style="margin-bottom: 0.5em">
                        The graphs down below show the performance of the final solution ran at 400, 4 000, and 40 000 boids.
                        Each graph also shows the performance with some different optimizations turned on or off.
                        <br>
                        <b>
                            Parallel/Singular = Jobs System On/Off<br>
                            Red/Blue = Burst Compiler On/Off
                        </b>
                    </p>
                </div>
                <div class="col-6 col-12-medium"><b class="image fit"><img loading="lazy" src="images/Boids/400.png" alt="" /></b></div>
                <div class="col-6 col-12-medium"><b class="image fit"><img loading="lazy" src="images/Boids/4000.png" alt="" /></b></div>
                <div class="col-6 col-12-medium" style="margin-left: auto; margin-right: auto"><b class="image fit" style="margin-bottom: 10px;"><img loading="lazy" src="images/Boids/40000.png" alt="" /></b>
                    <p style ="text-align: center">I was unable to get a number for Singular without Burst Compiler turned on at 40 000 boids as Unity would crash when trying.</p></div>
                <div class="col-12 col-12-medium">
                    <p>
                        As can be seen in the graphs, performance improves the more optimizations are enabled.
                        The improvements provided are also greater the higher the amount of boids is set to.
                        Something that may be of absence in the graphs is data with regard to the Unity ECS.
                        Unfortunately, I wasn't able to gather data as to how impactful the Unity ECS is as I don't have a non-ECS implementation to make fair comparisons to.
                    </p>
                    <p>
                        Something of interest in the results is how the Jobs System has a much greater impact for 4 000 and 40 000 boids than it does for 400 boids.
                        This can be explained by how the Jobs System divides work.
                        When a job is scheduled to run in parallel for a set amount of entities, it divides the work by creating multiple jobs which each pertain to a subset of those entities.
                        These jobs are distributed to worker threads in order to be able to run parallel with each other.
                        Each job may pertain up to a maximum of 128 entities, which has to do with how the Unity ECS stores up to 128 entities in a single memory chunk.
                        In practice, if a job were to be scheduled for 400 entities, it would result in 4 jobs distributed to 4 worker threads (if 4 worker threads are available).
                        If more than 4 workers threads are available, the additional ones simply remains unused.
                        Hence, the reason the impact of the Jobs System is greater for 4 000 boids than it is for 400 boids is that more worker threads have the chance to be utilized for 4 000 boids.
                    </p>
                    <p>
                        Another point of interest is how the Burst Compiler produces very similar results for all optimization combinations it's used in on the graph for 400 boids.
                        This is most likely just because it can rush through the code so fast at 400 boids that the majority of frametime just ends up going to other factors like rendering.
                        The contribution of other optimizations also probably becomes minimal compared to the Burst Compiler as they don't have as much of an opportunity to showcase their strength 
                        at 400 boids like they for the higher amounts.
                        The Job System has already been discussed as to why, but the reason for Spatial Hashing is that the O(nÂ²) time complexity without it doesn't become that significant of a 
                        problem at only 400 boids.
                    </p>
                </div>
            </div>

            <!-- Learn -->
            <div class="row gtr-150">
                <div class="col-12 col-12-medium"><h3>What I learned</h3>
                    <p>
                        I ended up learning quite a lot from this project.
                        It was my first time working with Multi-Threading, which is something that has been on my todo-list for a while now as I've long known
                        that it's an essential part of writing performant code.
                        In the end, it wasn't too scary apart from figuring out the syntax and what very descriptively named stuff like
                        <a href="https://docs.unity3d.com/Packages/com.unity.collections@0.2/api/Unity.Collections.IJobNativeMultiHashMapMergedSharedKeyIndices.html">IJobNativeMultiHashMapMergedSharedKeyIndices</a> does.
                        In addition to Multi-Threading, this project was also my first time working with an Entity Component System.
                        Prior to this project, I had never even heard of the concept of an ECS before, so it was completely uncharted territory to me.
                        Now, however, after having learned about it and what Data-Oriented Design is all about, I have become radicalized by the belief that 
                        Object-Oriented Programming is needlessly inefficient and wasteful compared to "real" programming which adheres to the blessed 
                        machine by prioritizing efficiency rather than human-readability.
                        This opinion of mine has nothing to do with randomly coming across a video of some guy on Youtube going on a passionate rant about why Object-Oriented 
                        Programming sucks and me being easily influenced.
                    </p>
                    <p>
                        The final aspect of this project that has been somewhat of a learning experience is the explicit focus it has had on implementing optimizations in general.
                        Performance is something that has always been taken into consideration throughout all the projects I've worked on, but it has been more so from the point 
                        of measuring it as that has typically been a requirement for assignments during my time at the University of SkÃ¶vde.
                        Of course, structuring code to be performant is something I always have in the back of my mind, but for this project specifically I got to go out of my way 
                        to just try and make something run as well as it can.
                        Through the process, I managed to learn of some nifty optimization tricks and techniques which brought me joy as they improved performance numbers.
                    </p>
                </div>
            </div>
        </div>
    </div>
</div>


<script src="assets/js/jquery.min.js"></script>
<script src="assets/js/jquery.scrolly.min.js"></script>
<script src="assets/js/jquery.dropotron.min.js"></script>
<script src="assets/js/jquery.scrollex.min.js"></script>
<script src="assets/js/browser.min.js"></script>
<script src="assets/js/breakpoints.min.js"></script>
<script src="assets/js/util.js"></script>
<script src="assets/js/main.js"></script>

</body>
</html>